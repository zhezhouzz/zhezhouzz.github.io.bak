<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Zhou Zhe&#39;s Home</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="keywords" content="Blog">
<meta property="og:type" content="website">
<meta property="og:title" content="Zhou Zhe&#39;s Home">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Zhou Zhe&#39;s Home">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Zhou Zhe&#39;s Home">
  
    <link rel="alternate" href="/atom.xml" title="Zhou Zhe&#39;s Home" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Zhou Zhe&#39;s Home</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-sdh-workflow-investigation" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/03/sdh-workflow-investigation/" class="article-date">
  <time datetime="2018-09-03T12:00:31.000Z" itemprop="datePublished">2018-09-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/03/sdh-workflow-investigation/">sdh-workflow-investigation</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="19-Tokenization"><a href="#19-Tokenization" class="headerlink" title="19: Tokenization"></a><em>19:</em> Tokenization</h4><ul>
<li>Simple, no AI. There is a <a href="https://spacy.io/usage/linguistic-features#how-tokenizer-works" target="_blank" rel="noopener">algorithm pseudo code</a> in spaCy website.</li>
<li>Basic operation and parallelization.<ul>
<li>splite and merge: splite the text by space, handle each part text, then merge. Could be parallelize.</li>
<li>search in database: to find if there is some specail cases match the text.</li>
<li>while lopp and logical judgment.</li>
</ul>
</li>
</ul>
<h4 id="22-Named-Entity-Recognition"><a href="#22-Named-Entity-Recognition" class="headerlink" title="22: Named Entity Recognition"></a><em>22:</em> Named Entity Recognition</h4><ul>
<li>AI algorithm. There is an <a href="https://github.com/explosion/spaCy/issues/2107" target="_blank" rel="noopener">issue</a> in the github that someone whated to konw the detail paper about spaCy <em>NER</em>(Entity Recognition). Honnibal, the author of spaCy NLP lib, said: <em>There’s no paper published, as the algorithm wasn’t designed for an academic contribution, and details are subject to change. The overall approach is quite similar to the paper by Strubell et al (2017): <a href="https://arxiv.org/abs/1702.02098" target="_blank" rel="noopener">https://arxiv.org/abs/1702.02098</a> . The main differences are that we use a different embedding method, a transition-based framework to facilitate imitation learning, and the convolutional layers use residual connections instead of dilation.</em></li>
<li>this paper, <a href="https://arxiv.org/pdf/1702.02098.pdf" target="_blank" rel="noopener">Fast and Accurate Entity Recognition with Iterated Dilated Convolutions</a>, use the iterated dilated CNN(spaCy said them use ResNet for instead).<ul>
<li>Use RNN instead of CNN(LSTMs) for RNN could use GPU to accelerate.</li>
<li>Use fixed depth convolutions.</li>
<li>14-20x speedups than Bi-LSTM-CRF.</li>
<li>spaCy use ResNet <a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a>, <a href="https://arxiv.org/pdf/1603.05027.pdf" target="_blank" rel="noopener">Identity Mappings in Deep Residual Networks</a>.</li>
</ul>
</li>
</ul>
<h4 id="46-Node-Classification"><a href="#46-Node-Classification" class="headerlink" title="46: Node Classification"></a><em>46:</em> Node Classification</h4><ul>
<li><a href="https://arxiv.org/pdf/1706.02216.pdf" target="_blank" rel="noopener">Inductive Representation Learning on Large Graphs</a>.<ul>
<li>Problem: node embeddings in dynamic graph, ml need a seqeunce of data: distill the high-dimensional information about a node’s graph neighborhood into a dense vector embedding.</li>
<li>previous works:  focused on embedding nodes from a single fixed graph, and many real-world applications require embeddings to be quickly generated for unseen nodes, or entirely new (sub)graphs. the weight matrices are not relevant between nodes.</li>
<li>contribution: simple neighborhood, aggreagate feature information from neighbos.<ul>
<li>first construct a graph of neighborhood with fix num _n_ (if neighbors numer greater than <em>max degree</em>, random drop some. if neighbors numer less than <em>max degree</em>, random reuse some).</li>
<li>embedding generation. for depth k:<ul>
<li>for each node v:<ul>
<li>AGGREGATE v’s neighbors(mean, GCN, LSTM, pooling).</li>
<li>concat the the old aggregation of loop k-1 and current aggregation.</li>
<li>use non-linearity _σ_ to transform the concated vector for next step.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>update: the author just change their words in <a href="https://github.com/williamleif/GraphSAGE/issues/13" target="_blank" rel="noopener">issue: Number nodes at each layers</a>. The code is correct.<ul>
<li>sample a “center” node, n0</li>
<li>sample 10 1-hop neighbors, n1</li>
<li>ample 25 1-hop neighbors of each n1, yielding 250 2-hop neighbors of n0</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="26-Recommender-System"><a href="#26-Recommender-System" class="headerlink" title="26: Recommender System"></a><em>26:</em> Recommender System</h4><ul>
<li><a href="https://github.com/amzn/amazon-dsstne" target="_blank" rel="noopener">mazon DSSTNE: Deep Scalable Sparse Tensor Network Engine</a><ul>
<li>Multi-GPU Scale: Training and prediction both scale out to use multiple GPUs, spreading out computation and storage in a model-parallel fashion for each layer.</li>
<li>Large Layers: Model-parallel scaling enables larger networks than are possible with a single GPU.</li>
<li>Sparse Data: DSSTNE is optimized for fast performance on sparse datasets, common in recommendation problems. Custom GPU kernels perform sparse computation on the GPU, without filling in lots of zeroes.</li>
</ul>
</li>
<li>About Recommender System itself, like a 4 layer fullyconnnected NN from <a href="https://gitlab.sdh.cloud/sdh-workflows/amazon-dsstne/blob/master/_sdh/model.json" target="_blank" rel="noopener">DSSTNE model config file</a>.</li>
<li>As the materails I found, it basicly is a <strong>Matrix completion problem:</strong> give a part of matrix, fill the rest. The recommender system example is <em>Netflix</em>: Netflix challenge offered in 2009 and carrying a 1M$ prize for the algorithm that can best predict user ratings for movies based on previous ratings. The size of the Netflix matrix is 480K movies and 18K users (8.5B elements), with only 0.011% known entries. There are some ml approach: <a href="https://arxiv.org/pdf/1704.06803.pdf" target="_blank" rel="noopener">Geometric Matrix Completion with Recurrent Multi-Graph Neural Networks</a>.</li>
</ul>
<h4 id="68-Changepoint-Detection"><a href="#68-Changepoint-Detection" class="headerlink" title="68: Changepoint Detection"></a><em>68:</em> Changepoint Detection</h4><ul>
<li><a href="https://arxiv.org/pdf/1209.1625.pdf" target="_blank" rel="noopener">Graph-Based Change-Point Detection</a>.<ul>
<li>Morden Statisticl problem: every element of a sequences is a high dimensional vector or even a non-Euclidean data object(graph like data). Example: Network evolution(<em>change in network of social interactions among individuals</em>), Image analysis(<em>The detection<br>of abrupt events, such as security breaches, storms, or brain activity</em>), Text or sequence analysis(writing style,  genomic sequence analysis in biology).</li>
</ul>
</li>
</ul>
<h4 id="Resolve-order"><a href="#Resolve-order" class="headerlink" title="Resolve order"></a>Resolve order</h4><ul>
<li><strong>Tokenization</strong>(simple) -&gt; <strong>Node Classification</strong>(easy to understand, has paper support) -&gt; <strong>Changepoint Detection</strong>(has paper support) -&gt; <strong>Named Entity Recognition</strong>(easy to understand, but no direct paper support) -&gt; <strong>Recommender System</strong>(no paper support)</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/03/sdh-workflow-investigation/" data-id="cjlm8gysu00052imc094icou5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/sdh/">sdh</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-reading-group-xy" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/31/reading-group-xy/" class="article-date">
  <time datetime="2018-08-31T19:06:18.000Z" itemprop="datePublished">2018-08-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/31/reading-group-xy/">reading_group_xy</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="Reluplex-An-Efficient-SMT-Solver-for-Verifying-Deep-Neural-Networks"><a href="#Reluplex-An-Efficient-SMT-Solver-for-Verifying-Deep-Neural-Networks" class="headerlink" title="Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks"></a>Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks</h4><ul>
<li><p><a href="https://arxiv.org/pdf/1702.01135.pdf" target="_blank" rel="noopener">Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks</a></p>
</li>
<li><p>To proof the NN is worked:</p>
<ul>
<li>In the past, we have some old algorithm besides deep learning, the reseachers design a very complex rule sets, which indicate what should a agent do when it in a situation. (A rule set restrict the input and output). But the data set is huge, and do bad when the agent meet the situation out of the rule set.</li>
<li>To improve this, we use the deep learning. The NN need a data set to train, and every instance of the data set just fellow this rules. But, also there is some undescovered rules are hidden in the data set. Then the NN could do the same things like the traditional algorithm, but also could handle the situation outside the rule sets.</li>
<li>However, we should prove that the NN do the same things like the old algorithm. And this is what it paper talking about. For each rule in the rule sets, we can convert it to a restriction to input and output. And this could be encode to a SMT problem, which could resolve by SMT solver.</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/08/31/reading-group-xy/" data-id="cjlidczfs00042i5vrofh5a23" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/31/2/" class="article-date">
  <time datetime="2018-08-31T16:57:03.000Z" itemprop="datePublished">2018-08-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/31/2/">Meeting in Aug 31, 2018</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="Important-Points"><a href="#Important-Points" class="headerlink" title="Important Points"></a>Important Points</h4><ul>
<li>Workflow Assignment:<ul>
<li><a href="https://spacy.io/" target="_blank" rel="noopener"><em>19:</em> Tokenization</a>: Segment text from strings of characters/symbols into linguistic units like words and sentences.</li>
<li><a href="https://spacy.io/" target="_blank" rel="noopener"><em>22:</em> Named Entity Recognition</a>: Classify named entities in text into pre-defined categories such as names, organizations, locations, quantities, monetary values, etc.  Can include chunking of multiple word into a single entity.</li>
<li><a href="https://github.com/amzn/amazon-dsstne/" target="_blank" rel="noopener"><em>26:</em> Recommender System</a>: Recommend items to a user given the user’s ratings and a dataset of ratings from other users.  This version uses Amazon’s neural network based DSSTNE framework on the MovieLens dataset.</li>
<li><a href="https://gitlab.sdh.cloud/sdh-workflows/graphSAGE" target="_blank" rel="noopener"><em>46:</em> Node Classification</a>: Learns graph embedding to predict the ages of individuals based on the known ages of their friends.</li>
<li><a href="https://gitlab.sdh.cloud/sdh-workflows/changepoint" target="_blank" rel="noopener"><em>68:</em> Changepoint Detection</a>: Uses scan statistics to determine where the distribution abruptly changes in a data sequence.</li>
</ul>
</li>
</ul>
<h4 id="Next-Week-Works"><a href="#Next-Week-Works" class="headerlink" title="Next Week Works"></a>Next Week Works</h4><ul>
<li><p>Read these workflow briefly, get the general understanding. try to sort them, choose the first one to analyze.</p>
</li>
<li><p>Investigate the interface between Ocaml, Python and C. Learn some Ocaml and Haskell…</p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/08/31/2/" data-id="cjli8qru500032i5vahy4anxk" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-first-post" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/29/first-post/" class="article-date">
  <time datetime="2018-08-29T19:51:33.000Z" itemprop="datePublished">2018-08-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/29/first-post/">Talk With Prof. Suresh in Aug 28, 2018</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h6 id="Works-Summary-of-Last-Week"><a href="#Works-Summary-of-Last-Week" class="headerlink" title="Works Summary of Last Week"></a>Works Summary of Last Week</h6><ul>
<li><strong>Clear the misunderstanding of approximate algorithm:</strong> the terminate state is not whole vertexs keep unchanged. We can tolerant a part of vertexs keep changing. So I introduce a new incoming argument _r_, which indicate the termination rate: if less than 1% of vertexs keep changing, then we can terminate the approximate algorithm.</li>
<li><strong>Fix the bug in kernel opencl:</strong> I had misused the <em>local memory</em> in opencl, now I have fixed it.</li>
<li><strong>Prepare the data set:</strong> I choose to use the format called <a href="https://math.nist.gov/MatrixMarket" target="_blank" rel="noopener">Matrix Market</a>. So I wrote a cpp code to transform the data format.</li>
<li><strong>Remove all dependency of Taco:</strong> The reason is that I find when <em>Taco</em> reading a matrix from disk, it try to malloc a huge memory and make a error. However, I think it should not use such memory, because for sparse matrix, the space to use is only related to the number of edges. Then, I want to rewrite the I/O part of <em>Taco</em>. But it bind tightly with the whole <em>data structure of tensor</em>. So I refactor the project and remove the all denpendency of <em>Taco</em>. Now, I design a tensor data structure by myself.</li>
</ul>
<h6 id="Talking-Content"><a href="#Talking-Content" class="headerlink" title="Talking Content"></a>Talking Content</h6><p><img src="/images/SDH.jpeg" alt="SDH" width="100%" height="100%"></p>
<h6 id="Works-Plan-of-Next-Week"><a href="#Works-Plan-of-Next-Week" class="headerlink" title="Works Plan of Next Week"></a>Works Plan of Next Week</h6><ul>
<li><strong>Improve the page rank algorithm:</strong> design the sparse version of approximate algorithm. which could make it run with huge data set(200k vertexs).</li>
<li><strong>Analyze the workflow:</strong> When DARPA decide three or four problem, we would try to analyze the problem. Maybe we would go to NEU.</li>
</ul>
<blockquote>
<p>The general information provided is expected to include identification of significant kernels/functions; algorithmic complexity; performance bottlenecks; description of data and any ETL requirements; opportunities for parallelization; and areas for optimization.  The performers are not expected to provide any information about performance of workloads on their proposed architectures.  If performance on an architecture is provided as part of the workflow analysis, it will be shared with the SDH community.</p>
</blockquote>
<ul>
<li><strong>Think about the procedure and data properties of page rank(and other problem): </strong> Deside use what kernel or algorithm by data properties in runtime.</li>
<li><strong>A result reusing problem:</strong> If we have got a partial result in one algorithm in one kernel, how can we transform the result to another algorithm in another kernel to resue this partial result.</li>
<li><strong>Preview the meta language:</strong> From Ocaml of Common Lisp.</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/08/29/first-post/" data-id="cjlfk3gjb00002i4mr07rt8gf" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/summary/">summary</a></li></ul>

    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/sdh/">sdh</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/summary/">summary</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/sdh/" style="font-size: 10px;">sdh</a> <a href="/tags/summary/" style="font-size: 10px;">summary</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/09/03/sdh-workflow-investigation/">sdh-workflow-investigation</a>
          </li>
        
          <li>
            <a href="/2018/08/31/reading-group-xy/">reading_group_xy</a>
          </li>
        
          <li>
            <a href="/2018/08/31/2/">Meeting in Aug 31, 2018</a>
          </li>
        
          <li>
            <a href="/2018/08/29/first-post/">Talk With Prof. Suresh in Aug 28, 2018</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Zhou Zhe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>